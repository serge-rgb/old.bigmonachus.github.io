---
layout: post
categories: [devlog]
title: "A real time ray tracing renderer for the Oculus Rift"
---

Real time ray tracing is about one of the coolest things you can work on. Add Virtual Reality to the mix and it just gets sweeter.


"Acid-RT" is a pet project of mine. It is a real time ray tracing renderer for the Oculus DK2 and it is [open source](http://github.com/bigmonachus/acid-rt).


<iframe src="//player.vimeo.com/video/118082317?color=c9ff23&title=0&portrait=0" width="600" height="316" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
_please excuse the short duration (fraps refused to record longer) and the rendering artifacts (a couple of overlapping polygons and a debug OBJ loader written in 15 minutes)_



Acid-RT is a wrapper around LibOVR. It operates at a higher level, acting as a graphics library for VR aplications. At this time, it is not suitable for general use, but it would be nice to get to that point.

This is not a post-mortem. I expect to continue working on this, but I feel that it has reached a point where I can write a good article and draw some conclusions.

If you want to skip the description [jump here](#end)

## Part 1. Detailed Description.
<hr/>

## 1.1 - Interfacing with LibOVR

At initialization time, Acid-RT calls all the appropriate LibOVR functions and get all the necessary info to get going.

It maintains state for all the geometry, and it handles rendering. The user specifies and updates geometry and camera info.

This project would not be possible if Oculus did not release the source code for LibOVR. It is a Good Thing that they do release it.

The standard way to integrate LibOVR into an engine involves creating a distortion mesh and setting up textures. Each frame, the engine is supposed to give LibOVR a framebuffer for each eye and ignore how the rest of the sausage gets made.

Acid-RT tries to avoid calling complex initialization functions as much as possible. It does the necessary initialization to give LibOVR access to the GL context and creates a couple of structures in order to obtain head pose information, as well as headset information such as how far away are the lens set from the eye, the size of the screen, the center of each lens, and the distortion coefficients.

## 1.2 - Lens distortion correction

Lens distortion is the first and most important challenge to solve. For performance reasons, LibOVR moved from a simple pixel shader in DK1 to a more complex mesh-based approach. Fortunately, after some digging, we can find out that the mesh is morphed by an equation, just as the DK1 had a simple cubic barrel distortion equation. At the time of this writing, it is an 10 point spline defined by 11 coefficients. If you are interested, you can google for "Cubic Hermite spline" and look for the definition of the Catmull-Rom spline.

Once we have a way to compute the spline from the 11 coefficients that define it, we can compute the distortion on a ray-by-ray basis. This is one place where ray tracing leads to more elegant solutions, by evaluating the spline, we are essentially bending the rays just as a corrective lens would. More on this later.

## 1.3 - Bounding Volume Hierarchies

<img src="http://i.imgur.com/Zn3kTcH.png" style="width: 600px;"/>

Acid-RT stores geometry data as "primitives": chunks of adjacent triangles. Meshes that are uploaded to the renderer get split into primitives and stripped of all other information.

The renderer stores a big soup of primitives, and a big soup of triangles. This info is passed to the GPU.

This "primitive soup" is used as input to construct a [BVH](http://en.wikipedia.org/wiki/Bounding_volume_hierarchy). This acceleration structure is by far the most popular and most researched structure in the real time ray tracing community. The method I use to build the BVH is the one you can find in the book "Physically Based Rendering", using the Surface Area Heuristic to create good trees.

It is generally considered that SBVH (Spatial Bounding Volume Hierarchy. Paper [here](http://www.nvidia.com/docs/IO/77714/sbvh.pdf)) is a more efficient way to construct a tree. It builds BVH trees in the usual way but it does some work to reduce overlapping of bounding boxes.

As I said, when Acid-RT loads meshes, it "shatters" them into primitives. To do that, it constructs an octree and creates primitives from every non-empty cell. This "octree shatter" method results in zero-overlap between primitive bounding boxes, which is the goal of SBVH. This means that I may have stumbled into a good alternative to SBVH, but I have yet to confirm if it is a better method or if it is terribly flawed. I was happy to learn that the "octree shatter" algorithm has a name, but I don't remember it right now.

## 1.4 - GL Compute vs OpenCL

The first implementation was based on OpenGL compute shaders. Compute shaders have the advantage over OpenCL or CUDA that they are guaranteed to be available if OpenGL 4.3 is supported; but I had to give them up because I wasn't getting the performance I wanted, and because on more than a couple of occasions I ran into shader compiler bugs.

I migrated to OpenCL and immediately got a about 5x speed boost. I got a lot of extra speed by tweaking for performance and experimenting with different traversal algorithms.

## 1.5 - Traversal algorithm

The most critical part of the ray tracer is the BVH traversal code. Most people who know what they are doing swear by this [fantastic paper](https://code.google.com/p/understanding-the-efficiency-of-ray-traversal-on-gpus/). Acid-RT uses a traversal algorithm based on that paper. I have done many optimizations to my implementation, but they all have been educated guesses followed by measuring. In order to speed things up effectively, I need to do actual profiling. Based on the paper I linked to and a back of the envelope calculation, I estimate that the renderer is a factor of 4 or 5 away from getting all the performance it can squeeze out of my GPU, more on this later.

The Compute ray tracer was limited by the stack size, so after migrating to OpenCL, one thing I tried was to implement stackless traversal ([paper here](http://onlinelibrary.wiley.com/doi/10.1111/cgf.12259/pdf)). It was an unsuccessful approach. It is much slower than the equivalent traversal algorithm that does maintain a stack. Almost certainly because it requires many more memory accesses.

I tried both the `if-if` and the `while-while` traversal methods described in the super-paper. `While-while` is much faster.

The world moves quickly. On my GPU, a GTX770, using MAD(multiply-add) intrinsics gives no measurable difference. A lot of presentations I stumbled upon suggested explicit MADs as an optimization technique.

## 1.6 - Anti-aliasing

Ray tracing is expensive, doubly so with VR. Multi-sampling is off the table. Acid-RT is currently using Screen Space Anti Aliasing. I took Timothy Lottes's FXAA code and used it for this. It works OK for smooth edges, but there is still a huge problem with sub-pixel aliasing. I have no solution for this other than multi-sampling.

<img src="http://i.imgur.com/6P7BmEq.png" style="width: 600px;"/>

_Sub pixel aliasing_

## 1.7 - Chromatic aberration correction

<img src="http://i.imgur.com/FQf3yrm.png" style="width: 600px;"/>

The way Acid-RT deals with chromatic aberration is by scaling each color component by a factor of the distance from the center of the lens. These 3 factors, for R, G, and B respectively, were determined "heuristically", which is a fancy way of saying that I tweaked them until things looked OK. This approach works pretty well. It works at least as well as what is currently done by LibOVR.

## 1.8 - Time warp


Time warp is a rotation done after the frame has been rendered but before vsync. It represents the difference in head orientation between the start of the frame and the point when it will be displayed on the screen. For Acid-RT, the rendered frame is a textured unit length quad; as simple as it gets. The implementation of timewarp is to just rotate the quad (with z=1) by the TimeWarp matrix.

# Part 2. GC and Crazy ideas
<hr/>
I started this project with garbage collection, using the Boehm GC. It gave me a lot of problems and I ended up ditching it almost completely.

The first problem was stability. I found a bug, and then found out that it had been reported about 10 years ago.
The other problem was obfuscation. Usually, simple mistakes with memory management come up immediately. With Boehm GC, they show up as difficult to understand errors deep within the codebase. Whenever that happened, I had to go up the call stack to see my mistake, instead of getting a nice friendly access violation crash.

I did a lot of crazy experiments. One of them was to divide the screen in a checker board pattern and, each frame, only draw either the odd squares or the even squares. The idea was to render half the pixels without reducing the resolution. This doubled the speed but caused very ugly artifacts. The experiment was more successful when I moved from squares to thin horizontal rectangles. The performance gain was not as dramatic, but it was not horrible. It looks kind of like the artifacs you see when you convert interlaced video to digital formats.

Right now I am rendering to a smaller backbuffer and then resampling to 1080p. With linear resampling this doesn't look too bad and it gives the 2x boost that I currently need. I hope that a nicer resampling would make this a viable way to do things.

<a name="end"></a>

# Part 3. Future work.
<hr/>

* The next thing I plan to do is to switch to direct mode. Right now Acid-RT works only in "extended-mode", which means the Rift is acting as a secondary display. This reportedly gives at least one frame of extra latency, but I haven't measured it. I see the similar latency to my renderer when I play something like Elite: Dangerous, which runs on extended-mode. I would really like my renderer to run as perfectly as the Oculus samples.

* I need to switch to CUDA, even if that means supporting NVidia only. Like Mike Acton said, different hardware means different problem. OpenCL is too absracted away and there are no useful tools for me to speed up the ray tracer. I need CUDA to reduce the gap between the performance I am getting and the theoretical limit.

* Right now, OpenCL and OpenGL are sharing the backbuffer texture. By being less sophisticated and disabling sharing, asynchronous timewarp would be relatively easy to implement.

* I want to return to the checkerboard experiment, and use two-frame timewarp matrices. Fresh tiles get one-frame timewarped, and old tiles get two-frame timewarped. This would reduce the artifacts, hopefully by a lot. Probably fun to try out.

* I want to write a simple program that is bigger than a sample but smaller than a game, so that I can implement features like dynamic lighting and animation the right way.

* The distortion that LibOVR uses is not perfect. With ray-by-ray calculation, it could be a perfect inverse effect of the lens distortion. This is the hardest challenge in this list because I am ignorant about optics and a lot of important information is probably a trade secret.

# Part 4. Conclusions
<hr/>

The advantage of ray tracing is that most problems become simpler, with the notable exception of dynamic scenes.

Today, there is no practical reason to use ray tracing instead of rasterization for VR applications. Although simplicity is always nice, the end-user will not directly benefit from a tidier, prettier codebase, and the cases where ray tracing benefits are visible to the user probably won't show up in something as computationally demanding as VR.

That said, I can see a simple game implemented with something like what I have here. It might consume more resources than necessary, but as long as it runs at more than 75 or 90 FPS then no one will get hurt; and the programmer's soul won't be as damaged from OpenGL exposure.

I expected lens distortion to get simpler with ray tracing, and it did, but pretty much every feature has been simple to implement. Async timewarp seems to be an easy thing to add too, which is definitely not the case for the traditional way.

An advantage of ray tracing over rasterization is that there is no need to draw to a huge buffer so that it can distort gracefully; we are essentially just bending light.

Real time ray tracing is still very young. A lot of the ground breaking research is still recent and many old ideas are still valid. It is an field that will only get more exciting as GPUs and CPUs continue to converge. Maybe it does have a place in VR.



